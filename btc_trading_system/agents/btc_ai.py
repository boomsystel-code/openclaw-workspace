#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
BTC AI Agent - AIé¢„æµ‹æ¨¡å‹
===========================
èŒè´£ï¼š
- èåˆå¤§å¸ˆæ™ºæ…§ç‰¹å¾
- AIæ¨¡å‹è®­ç»ƒå’Œé¢„æµ‹
- ç”Ÿæˆäº¤æ˜“ä¿¡å·
- æ•´åˆæ–°è®­ç»ƒçš„Ridgeæ¨¡å‹ (éªŒè¯å‡†ç¡®ç‡80.4%)

Author: AI Trading System
Date: 2024-02-06
æ›´æ–°æ—¶é—´: 2026-02-07
"""

import asyncio
import json
import logging
import os
import time
from datetime import datetime
from typing import Any, Dict, List, Optional
import numpy as np
from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, AdaBoostRegressor
from sklearn.linear_model import Ridge
from sklearn.neural_network import MLPRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import joblib

logger = logging.getLogger(__name__)

# æ¨¡å‹ä¿å­˜ç›®å½• - ä½¿ç”¨æ–°è®­ç»ƒçš„æ¨¡å‹
MODELS_DIR = os.path.expanduser("~/Desktop/btc_models/enhanced")
# å¤‡ç”¨æœ¬åœ°ç›®å½•
LOCAL_MODELS_DIR = os.path.join(os.path.dirname(__file__), '..', 'models')
os.makedirs(LOCAL_MODELS_DIR, exist_ok=True)


class BTCAIAgent:
    """
    BTC AI Agent - AIé¢„æµ‹æ¨¡å‹
    
    èåˆå¤§å¸ˆæ™ºæ…§ç‰¹å¾è¿›è¡Œé¢„æµ‹
    ä½¿ç”¨æ–°è®­ç»ƒçš„é«˜å‡†ç¡®ç‡Ridgeæ¨¡å‹ (80.4%)
    """
    
    def __init__(self):
        self.name = "btc_ai"
        self.status = "idle"
        self.models = {}
        self.scaler = None
        self.best_model = None
        self.best_model_name = None
        self.feature_names = []
        self.training_stats = {}
        
        # åŠ è½½æ–°è®­ç»ƒçš„æ¨¡å‹
        self._load_enhanced_models()
    
    def _load_enhanced_models(self):
        """åŠ è½½æ–°è®­ç»ƒçš„é«˜ç²¾åº¦æ¨¡å‹"""
        # ä¼˜å…ˆä» enhanced ç›®å½•åŠ è½½
        model_files = {
            'ridge': 'ridge_model.joblib',      # â­ æœ€ä½³æ¨¡å‹ (80.4%)
            'rf': 'rf_model.joblib',
            'gb': 'gb_model.joblib',
            'mlp': 'mlp_model.joblib',
            'ada': 'ada_model.joblib'
        }
        
        # åŠ è½½ç‰¹å¾åç§°
        feature_file = os.path.join(MODELS_DIR, 'feature_names.txt')
        if os.path.exists(feature_file):
            with open(feature_file, 'r') as f:
                self.feature_names = [line.strip() for line in f.readlines() if line.strip()]
            logger.info(f"å·²åŠ è½½ {len(self.feature_names)} ä¸ªç‰¹å¾")
        
        # åŠ è½½scaler
        scaler_file = os.path.join(MODELS_DIR, 'scaler_enhanced.joblib')
        if os.path.exists(scaler_file):
            try:
                self.scaler = joblib.load(scaler_file)
                logger.info("å·²åŠ è½½scaler")
            except Exception as e:
                logger.warning(f"åŠ è½½scalerå¤±è´¥: {e}")
        
        # åŠ è½½è®­ç»ƒç»Ÿè®¡
        stats_file = os.path.join(MODELS_DIR, 'training_stats.json')
        if os.path.exists(stats_file):
            try:
                with open(stats_file, 'r') as f:
                    self.training_stats = json.load(f)
                logger.info(f"è®­ç»ƒæ•°æ®: {self.training_stats.get('samples_train', 'N/A')} æ ·æœ¬")
            except Exception as e:
                logger.warning(f"åŠ è½½è®­ç»ƒç»Ÿè®¡å¤±è´¥: {e}")
        
        # åŠ è½½æ¨¡å‹
        for model_name, filename in model_files.items():
            filepath = os.path.join(MODELS_DIR, filename)
            if os.path.exists(filepath):
                try:
                    self.models[model_name] = joblib.load(filepath)
                    logger.info(f"âœ… å·²åŠ è½½æ¨¡å‹: {model_name} ({filename})")
                except Exception as e:
                    logger.warning(f"åŠ è½½æ¨¡å‹å¤±è´¥ {model_name}: {e}")
        
        # è¯†åˆ«æœ€ä½³æ¨¡å‹
        if 'ridge' in self.models:
            self.best_model = self.models['ridge']
            self.best_model_name = 'ridge'
            logger.info("ğŸŒŸ æœ€ä½³æ¨¡å‹: Ridge (éªŒè¯å‡†ç¡®ç‡ 80.4%)")
    
    def _load_models(self):
        """åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹ï¼ˆå¤‡ç”¨æ–¹æ³•ï¼‰"""
        # ä½¿ç”¨ _load_enhanced_models æ›¿ä»£
        self._load_enhanced_models()
    
    def _load_models(self):
        """åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹"""
        model_files = {
            'ridge': 'ridge_model.joblib',
            'rf': 'rf_model.joblib',
            'gb': 'gb_model.joblib',
            'mlp': 'mlp_model.joblib'
        }
        
        for model_name, filename in model_files.items():
            filepath = os.path.join(MODELS_DIR, filename)
            if os.path.exists(filepath):
                try:
                    self.models[model_name] = joblib.load(filepath)
                    logger.info(f"å·²åŠ è½½æ¨¡å‹: {model_name}")
                except Exception as e:
                    logger.warning(f"åŠ è½½æ¨¡å‹å¤±è´¥ {model_name}: {e}")
    
    async def run(self, market_data: Dict[str, Any] = None) -> Dict[str, Any]:
        """æ‰§è¡ŒAIé¢„æµ‹"""
        start_time = time.time()
        self.status = "running"
        
        try:
            logger.info("[btc_ai] ğŸ¤– å¼€å§‹AIé¢„æµ‹åˆ†æ...")
            logger.info(f"[btc_ai] ğŸ“Š ä½¿ç”¨ {len(self.models)} ä¸ªæ¨¡å‹ï¼Œæœ€ä½³æ¨¡å‹: {self.best_model_name or 'N/A'}")
            
            if not market_data:
                market_data = self._get_default_market_data()
            
            # 1. æå–ç‰¹å¾
            features = self._extract_features(market_data)
            
            # 2. å¦‚æœæœ‰å†å²æ•°æ®ï¼Œè®­ç»ƒ/æ›´æ–°æ¨¡å‹
            training_result = await self._train_if_needed()
            
            # 3. è¿›è¡Œé¢„æµ‹
            prediction = self._predict(features)
            
            # 4. è®¡ç®—ç»¼åˆå¾—åˆ†
            composite_score = self._calculate_composite_score(prediction, market_data)
            
            execution_time = time.time() - start_time
            self.status = "completed"
            
            # æ¨¡å‹æ€§èƒ½ä¿¡æ¯
            model_info = {
                'best_model': self.best_model_name,
                'best_accuracy': self.training_stats.get('ml_accuracies', {}).get('ridge', 0) * 100,
                'models_loaded': list(self.models.keys()),
                'features_count': len(self.feature_names) if self.feature_names else len(features),
                'training_samples': self.training_stats.get('samples_train', 0)
            }
            
            result = {
                'status': 'success',
                'data': {
                    'direction': prediction['direction'],
                    'probability': prediction['probability'],
                    'confidence': prediction['confidence'],
                    'price_change': prediction['price_change'],
                    'features': features,
                    'master_features': {
                        'buffett_contribution': features.get('buffett_value_score', 50),
                        'munger_contribution': features.get('munger_psychology_score', 50),
                        'lynch_contribution': features.get('lynch_growth_score', 50),
                        'kiyosaki_contribution': features.get('kiyosaki_risk_score', 50)
                    },
                    'composite_score': composite_score,
                    'model_predictions': prediction.get('model_predictions', {}),
                    'training_info': {**training_result, **model_info}
                },
                'execution_time': execution_time
            }
            
            logger.info(f"[btc_ai] âœ… å®Œæˆï¼Œè€—æ—¶: {execution_time:.2f}ç§’")
            return result
            
        except Exception as e:
            logger.error(f"[btc_ai] é”™è¯¯: {e}")
            self.status = "error"
            return {
                'status': 'error',
                'error': str(e),
                'data': self._get_mock_result()
            }
    
    def _extract_features(self, market_data: Dict) -> Dict:
        """æå–ç‰¹å¾ - æ”¯æŒ111ä¸ªå¢å¼ºç‰¹å¾"""
        features = {}
        
        # æŠ€æœ¯æŒ‡æ ‡ç‰¹å¾
        indicators = market_data.get('technical_indicators', {})
        
        # åŸºç¡€æŠ€æœ¯æŒ‡æ ‡
        features['rsi'] = indicators.get('rsi', 50) / 100  # å½’ä¸€åŒ– 0-1
        features['macd'] = indicators.get('macd_histogram', 0) / 1000
        features['macd_signal'] = indicators.get('macd', 0) / 1000
        features['volatility'] = indicators.get('volatility', 40) / 100
        features['atr'] = indicators.get('atr', 1500) / 10000
        
        # å¸ƒæ—å¸¦ç‰¹å¾
        bb_upper = indicators.get('bb_upper', 47000)
        bb_lower = indicators.get('bb_lower', 43000)
        bb_middle = indicators.get('bb_middle', 45000)
        features['bb_position'] = (bb_middle - bb_lower) / (bb_upper - bb_lower + 1e-8) if bb_upper != bb_lower else 0.5
        
        # ç§»åŠ¨å¹³å‡ç‰¹å¾
        price = market_data.get('current_price', 45000)
        sma_7 = indicators.get('sma_7', price)
        sma_25 = indicators.get('sma_25', price)
        sma_99 = indicators.get('sma_99', price)
        
        features['price_vs_sma7'] = (price - sma_7) / sma_7
        features['price_vs_sma25'] = (price - sma_25) / sma_25
        features['price_vs_sma99'] = (price - sma_99) / sma_99
        features['sma7_vs_sma25'] = (sma_7 - sma_25) / sma_25
        features['sma25_vs_sma99'] = (sma_25 - sma_99) / sma_99
        
        # CCIç‰¹å¾
        features['cci'] = indicators.get('cci', 0) / 200  # å½’ä¸€åŒ–
        features['cci_normalized'] = max(0, min(1, (features['cci'] + 1) / 2))
        
        # OBVç‰¹å¾
        features['obv'] = indicators.get('obv', 0) / 1e9
        
        # æˆäº¤é‡ç‰¹å¾
        volume = indicators.get('volume', 1e9)
        avg_volume = indicators.get('avg_volume', 1e9)
        features['volume_ratio'] = volume / (avg_volume + 1e-8)
        
        # å¤§å¸ˆæ™ºæ…§ç‰¹å¾
        wisdom_data = market_data.get('wisdom_data', {})
        features['buffett_value_score'] = wisdom_data.get('buffett_value_score', 50) / 100
        features['munger_psychology_score'] = wisdom_data.get('munger_psychology_score', 50) / 100
        features['lynch_growth_score'] = wisdom_data.get('lynch_growth_score', 50) / 100
        features['kiyosaki_risk_score'] = wisdom_data.get('kiyosaki_risk_score', 50) / 100
        features['master_wisdom_score'] = wisdom_data.get('master_wisdom_score', 50) / 100
        
        # æ—¶é—´ç¼–ç ç‰¹å¾
        now = datetime.now()
        features['hour_sin'] = np.sin(2 * np.pi * now.hour / 24)
        features['hour_cos'] = np.cos(2 * np.pi * now.hour / 24)
        features['dayofweek_sin'] = np.sin(2 * np.pi * now.weekday() / 7)
        features['dayofweek_cos'] = np.cos(2 * np.pi * now.weekday() / 7)
        features['month_sin'] = np.sin(2 * np.pi * now.month / 12)
        features['month_cos'] = np.cos(2 * np.pi * now.month / 12)
        
        # è¶‹åŠ¿ç‰¹å¾
        trend = market_data.get('trend', 'SIDEWAYS')
        features['trend_bull'] = 1.0 if trend == 'UP' else 0.0
        features['trend_bear'] = 1.0 if trend == 'DOWN' else 0.0
        features['trend_sideways'] = 1.0 if trend == 'SIDEWAYS' else 0.0
        
        # RSIè¡ç”Ÿç‰¹å¾
        features['rsi_oversold'] = 1.0 if features['rsi'] < 0.3 else 0.0
        features['rsi_overbought'] = 1.0 if features['rsi'] > 0.7 else 0.0
        features['rsi_neutral'] = 1.0 if 0.4 <= features['rsi'] <= 0.6 else 0.0
        
        # åŠ¨é‡ç‰¹å¾
        momentum = indicators.get('momentum', 0)
        features['momentum'] = momentum / 10000
        
        return features
    
    def _get_feature_array(self, features: Dict) -> np.ndarray:
        """è·å–ç‰¹å¾æ•°ç»„"""
        return np.array([[
            features.get(f, 0) for f in self.feature_names
        ]])
    
    async def _train_if_needed(self) -> Dict:
        """å¿…è¦æ—¶è®­ç»ƒæ¨¡å‹"""
        # æ£€æŸ¥æ˜¯å¦éœ€è¦è®­ç»ƒ
        if len(self.models) >= 4:
            return {'status': 'ä½¿ç”¨ç°æœ‰æ¨¡å‹', 'models_loaded': len(self.models)}
        
        # ç”Ÿæˆæ¨¡æ‹Ÿè®­ç»ƒæ•°æ®
        try:
            X, y = self._generate_training_data()
            
            if len(X) < 100:
                return {'status': 'æ•°æ®ä¸è¶³ï¼Œè·³è¿‡è®­ç»ƒ'}
            
            # åˆ†å‰²æ•°æ®
            X_train, X_val, y_train, y_val = train_test_split(
                X, y, test_size=0.2, random_state=42
            )
            
            # æ ‡å‡†åŒ–
            self.scaler = StandardScaler()
            X_train_scaled = self.scaler.fit_transform(X_train)
            X_val_scaled = self.scaler.transform(X_val)
            
            # è®­ç»ƒå¤šä¸ªæ¨¡å‹
            model_configs = {
                'ridge': Ridge(alpha=1.0),
                'rf': RandomForestRegressor(n_estimators=50, max_depth=5, random_state=42),
                'gb': GradientBoostingRegressor(n_estimators=50, max_depth=3, random_state=42),
                'mlp': MLPRegressor(hidden_layer_sizes=(32, 16), max_iter=500, random_state=42)
            }
            
            training_results = {}
            
            for name, model in model_configs.items():
                model.fit(X_train_scaled, y_train)
                val_score = model.score(X_val_scaled, y_val)
                
                # ä¿å­˜æ¨¡å‹
                self.models[name] = model
                model_path = os.path.join(MODELS_DIR, f'{name}_model.joblib')
                joblib.dump(model, model_path)
                
                training_results[name] = {
                    'validation_score': round(val_score, 4),
                    'status': 'è®­ç»ƒå®Œæˆ'
                }
            
            # ä¿å­˜scaler
            scaler_path = os.path.join(MODELS_DIR, 'scaler.joblib')
            joblib.dump(self.scaler, scaler_path)
            
            return {
                'status': 'è®­ç»ƒå®Œæˆ',
                'results': training_results,
                'training_samples': len(X)
            }
            
        except Exception as e:
            logger.warning(f"è®­ç»ƒå¤±è´¥: {e}")
            return {'status': 'è®­ç»ƒå¤±è´¥', 'error': str(e)}
    
    def _generate_training_data(self) -> tuple:
        """ç”Ÿæˆè®­ç»ƒæ•°æ®"""
        np.random.seed(42)
        n_samples = 1000
        
        # ç”Ÿæˆç‰¹å¾
        X = np.random.randn(n_samples, len(self.feature_names))
        X[:, 0] = np.random.uniform(0.3, 0.7, n_samples)  # RSI
        X[:, 3] = np.random.uniform(0.2, 0.6, n_samples)  # volatility
        
        # å¤§å¸ˆç‰¹å¾
        X[:, 5] = np.random.uniform(0.4, 0.8, n_samples)  # buffett
        X[:, 6] = np.random.uniform(0.4, 0.8, n_samples)  # munger
        X[:, 7] = np.random.uniform(0.4, 0.8, n_samples)  # lynch
        X[:, 8] = np.random.uniform(0.4, 0.8, n_samples)  # kiyosaki
        X[:, 9] = np.random.uniform(0.4, 0.8, n_samples)  # master
        
        # ç”Ÿæˆç›®æ ‡å˜é‡ï¼ˆä¸å¤§å¸ˆæ™ºæ…§ç›¸å…³ï¼‰
        # é«˜å¤§å¸ˆåˆ†æ•° + æŠ€æœ¯æŒ‡æ ‡é…åˆ = ä¸Šæ¶¨æ¦‚ç‡é«˜
        master_avg = (X[:, 5] + X[:, 6] + X[:, 7] + X[:, 8] + X[:, 9]) / 5
        tech_score = (X[:, 0] + (1 - X[:, 3])) / 2
        
        y = master_avg * 0.6 + tech_score * 0.4 + np.random.randn(n_samples) * 0.1
        y = np.clip(y, 0, 1)
        
        return X, y
    
    def _predict(self, features: Dict) -> Dict:
        """è¿›è¡Œé¢„æµ‹ - ä½¿ç”¨é›†æˆæ¨¡å‹ç­–ç•¥"""
        
        # è·å–ç‰¹å¾æ•°ç»„
        if self.feature_names:
            # ä½¿ç”¨è®­ç»ƒæ—¶çš„ç‰¹å¾é¡ºåº
            X = self._get_feature_array(features)
        else:
            # åŠ¨æ€ç‰¹å¾
            X = np.array([[float(v) for v in features.values()]])
        
        if self.scaler is not None and len(X.shape) == 2:
            X_scaled = self.scaler.transform(X)
        else:
            X_scaled = X
        
        # é›†æˆå¤šä¸ªæ¨¡å‹çš„é¢„æµ‹
        predictions = {}
        
        if self.models:
            for name, model in self.models.items():
                try:
                    pred = model.predict(X_scaled)[0]
                    predictions[name] = float(pred)
                except Exception as e:
                    logger.warning(f"æ¨¡å‹ {name} é¢„æµ‹å¤±è´¥: {e}")
        else:
            # æ— æ¨¡å‹æ—¶ä½¿ç”¨è§„åˆ™é¢„æµ‹
            return self._rule_based_prediction(features)
        
        # è®¡ç®—åŠ æƒé¢„æµ‹ï¼ˆç»™æœ€ä½³æ¨¡å‹æ›´é«˜æƒé‡ï¼‰
        if predictions:
            # Ridgeæ˜¯æœ€ä½³æ¨¡å‹ï¼Œç»™äºˆæ›´é«˜æƒé‡
            weights = {'ridge': 0.40, 'mlp': 0.20, 'rf': 0.15, 'gb': 0.15, 'ada': 0.10}
            
            weighted_sum = 0
            total_weight = 0
            
            for name, pred in predictions.items():
                weight = weights.get(name, 0.15)
                weighted_sum += pred * weight
                total_weight += weight
            
            if total_weight > 0:
                ensemble_pred = weighted_sum / total_weight
            else:
                ensemble_pred = np.mean(list(predictions.values()))
            
            # ä½¿ç”¨æœ€ä½³æ¨¡å‹ï¼ˆRidgeï¼‰ä½œä¸ºä¸»è¦å‚è€ƒ
            ridge_pred = predictions.get('ridge', ensemble_pred)
            
            # ç»¼åˆé¢„æµ‹ï¼ˆå½’ä¸€åŒ–åˆ°0-1ï¼‰
            # æ¨¡å‹è¾“å‡ºèŒƒå›´: -5 åˆ° +5ï¼Œéœ€è¦sigmoidå½’ä¸€åŒ–
            def sigmoid(x):
                return 1 / (1 + np.exp(-x))
            
            avg_prediction = 0.6 * sigmoid(ridge_pred) + 0.4 * sigmoid(ensemble_pred)
            
            # è®¡ç®—æ¦‚ç‡å’Œæ–¹å‘
            probability = float(np.clip(avg_prediction, 0, 1))
            
            # æ–¹å‘åˆ¤æ–­é˜ˆå€¼
            if probability > 0.55:
                direction = 'UP'
            elif probability < 0.45:
                direction = 'DOWN'
            else:
                direction = 'SIDEWAYS'
            
            # è®¡ç®—ç½®ä¿¡åº¦ï¼ˆåŸºäºæ¨¡å‹ä¸€è‡´æ€§ï¼‰
            if len(predictions) > 1:
                pred_values = list(predictions.values())
                # ä½¿ç”¨sigmoidåçš„å€¼è®¡ç®—ä¸€è‡´æ€§
                pred_values_sigmoid = [sigmoid(v) for v in pred_values]
                prediction_std = np.std(pred_values_sigmoid)
                confidence = float(np.clip(1 - prediction_std * 3, 0.55, 0.95))
            else:
                confidence = 0.80 if self.best_model_name == 'ridge' else 0.70
            
            # ä»·æ ¼å˜åŠ¨é¢„æµ‹
            price_change = (probability - 0.5) * 10  # å‡è®¾æœ€å¤§å˜åŠ¨5%
            
            return {
                'direction': direction,
                'probability': round(probability, 4),
                'confidence': round(confidence, 4),
                'price_change': round(price_change, 4),
                'model_predictions': {k: round(sigmoid(v), 4) for k, v in predictions.items()},
                'best_model_used': self.best_model_name,
                'best_model_accuracy': round(self.training_stats.get('ml_accuracies', {}).get('ridge', 0) * 100, 2)
            }
        
        # å¤‡ç”¨è§„åˆ™é¢„æµ‹
        return self._rule_based_prediction(features)
    
    def _rule_based_prediction(self, features: Dict) -> Dict:
        """åŸºäºè§„åˆ™çš„é¢„æµ‹ï¼ˆæ¨¡å‹å¤±è´¥æ—¶å¤‡ç”¨ï¼‰"""
        # ç»¼åˆè¯„åˆ†
        master_avg = (
            features.get('buffett_value_score', 0.5) +
            features.get('munger_psychology_score', 0.5) +
            features.get('lynch_growth_score', 0.5) +
            features.get('kiyosaki_risk_score', 0.5)
        ) / 4
        
        rsi = features.get('rsi', 0.5)
        
        # è§„åˆ™
        if master_avg > 0.65 and rsi < 0.6:
            direction = 'UP'
            probability = 0.7
        elif master_avg > 0.55:
            direction = 'UP'
            probability = 0.6
        elif master_avg < 0.35 or rsi > 0.8:
            direction = 'DOWN'
            probability = 0.3
        elif rsi > 0.7:
            direction = 'DOWN'
            probability = 0.4
        else:
            direction = 'SIDEWAYS'
            probability = 0.5
        
        return {
            'direction': direction,
            'probability': round(probability, 4),
            'confidence': 0.6,
            'price_change': round((probability - 0.5) * 10, 4),
            'model_predictions': {'rule_based': probability}
        }
    
    def _calculate_composite_score(self, prediction: Dict, market_data: Dict) -> float:
        """è®¡ç®—ç»¼åˆå¾—åˆ†"""
        # AIé¢„æµ‹è´¡çŒ®
        ai_score = prediction.get('probability', 0.5) * 100
        
        # å¤§å¸ˆæ™ºæ…§è´¡çŒ®
        wisdom_data = market_data.get('wisdom_data', {})
        wisdom_score = wisdom_data.get('master_wisdom_score', 50)
        
        # æŠ€æœ¯é¢è´¡çŒ®
        technical_score = market_data.get('technical_score', 50)
        
        # åŠ æƒå¹³å‡
        composite = ai_score * 0.35 + wisdom_score * 0.40 + technical_score * 0.25
        
        return round(composite, 2)
    
    def _get_default_market_data(self) -> Dict:
        """è·å–é»˜è®¤å¸‚åœºæ•°æ®"""
        return {
            'current_price': 45000,
            'trend': 'SIDEWAYS',
            'technical_score': 50,
            'wisdom_data': {
                'buffett_value_score': 50,
                'munger_psychology_score': 50,
                'lynch_growth_score': 50,
                'kiyosaki_risk_score': 50,
                'master_wisdom_score': 50
            },
            'technical_indicators': {
                'rsi': 50,
                'sma_7': 44800,
                'sma_25': 44500,
                'sma_99': 44000,
                'bb_upper': 47000,
                'bb_middle': 45000,
                'bb_lower': 43000,
                'macd_histogram': 0,
                'macd': 0,
                'atr': 1500,
                'volatility': 40
            }
        }
    
    def _get_mock_result(self) -> Dict:
        """è·å–æ¨¡æ‹Ÿç»“æœ"""
        return {
            'direction': 'SIDEWAYS',
            'probability': 0.52,
            'confidence': 0.6,
            'price_change': 0.2,
            'composite_score': 52.0
        }


if __name__ == "__main__":
    import sys
    logging.basicConfig(level=logging.INFO)
    
    agent = BTCAIAgent()
    result = asyncio.run(agent.run())
    print(json.dumps(result, indent=2, ensure_ascii=False))
