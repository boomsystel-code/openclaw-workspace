#!/usr/bin/env python3
"""
ğŸš€ OpenClaw AI åŠ©æ‰‹ - ä»»åŠ¡æ‰§è¡Œå™¨
ä¸“é—¨æ‰§è¡Œå„ç§AIç›¸å…³ä»»åŠ¡çš„æ¨¡å—
"""

import os
import sys
import json
import time
import subprocess
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Callable
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class TaskExecutor:
    """ä»»åŠ¡æ‰§è¡Œå™¨ - çœŸæ­£èƒ½å¹²æ´»çš„æ ¸å¿ƒ"""
    
    def __init__(self, workspace: str = "/Users/wangshice/.openclaw/workspace"):
        self.workspace = Path(workspace)
        self.tasks_log = self.workspace / "task_execution_log.json"
        self.results_dir = self.workspace / "task_results"
        self.results_dir.mkdir(exist_ok=True)
        
        # åŠ è½½æ‰§è¡Œå†å²
        self.execution_history = self.load_history()
        
        # æ³¨å†Œä»»åŠ¡å¤„ç†å™¨
        self.task_handlers = {
            "æ•°æ®åˆ†æ": self.task_data_analysis,
            "æœºå™¨å­¦ä¹ ": self.task_machine_learning,
            "æ·±åº¦å­¦ä¹ ": self.task_deep_learning,
            "NLPä»»åŠ¡": self.task_nlp,
            "ç¼–å†™ä»£ç ": self.task_write_code,
            "ä»£ç è°ƒè¯•": self.task_debug_code,
            "å­¦ä¹ æ–°çŸ¥è¯†": self.task_learn_knowledge,
            "æ›´æ–°çŸ¥è¯†åº“": self.task_update_knowledge,
            "ç”ŸæˆæŠ¥å‘Š": self.task_generate_report,
            "æ–‡ä»¶æ•´ç†": self.task_organize_files,
            "ç½‘ç»œæœç´¢": self.task_web_search,
            "è¿è¡Œè„šæœ¬": self.task_run_script,
        }
        
        logger.info("ğŸš€ TaskExecutor å·²å°±ç»ª")
    
    def load_history(self) -> List[Dict]:
        """åŠ è½½æ‰§è¡Œå†å²"""
        if self.tasks_log.exists():
            with open(self.tasks_log, 'r', encoding='utf-8') as f:
                return json.load(f)
        return []
    
    def save_history(self):
        """ä¿å­˜æ‰§è¡Œå†å²"""
        with open(self.tasks_log, 'w', encoding='utf-8') as f:
            json.dump(self.execution_history, f, ensure_ascii=False, indent=2)
    
    def log_execution(self, task: str, status: str, details: Dict = None):
        """è®°å½•æ‰§è¡Œæ—¥å¿—"""
        entry = {
            "timestamp": datetime.now().isoformat(),
            "task": task,
            "status": status,
            "details": details or {}
        }
        self.execution_history.append(entry)
        self.save_history()
        logger.info(f"ğŸ“ æ‰§è¡Œè®°å½•: {task} -> {status}")
    
    def execute(self, task_type: str, params: Dict) -> Dict:
        """æ‰§è¡Œä»»åŠ¡"""
        logger.info(f"ğŸ¯ æ‰§è¡Œä»»åŠ¡: {task_type} | å‚æ•°: {params}")
        
        if task_type in self.task_handlers:
            try:
                result = self.task_handlers[task_type](params)
                self.log_execution(task_type, "success", result)
                return {"status": "success", "result": result}
            except Exception as e:
                logger.error(f"âŒ ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
                self.log_execution(task_type, "failed", {"error": str(e)})
                return {"status": "failed", "error": str(e)}
        else:
            logger.warning(f"âš ï¸ æœªçŸ¥ä»»åŠ¡ç±»å‹: {task_type}")
            return {"status": "unknown", "error": f"æœªçŸ¥ä»»åŠ¡ç±»å‹: {task_type}"}
    
    # ==================== ä»»åŠ¡å¤„ç†å™¨ ====================
    
    def task_data_analysis(self, params: Dict) -> Dict:
        """æ•°æ®åˆ†æä»»åŠ¡"""
        logger.info("ğŸ“Š æ‰§è¡Œæ•°æ®åˆ†æä»»åŠ¡...")
        
        result = {
            "task": "data_analysis",
            "executed_at": datetime.now().isoformat(),
            "actions": [],
            "outputs": []
        }
        
        # ç¤ºä¾‹ï¼šåˆ†ææ•°æ®æ–‡ä»¶
        data_file = params.get("file")
        if data_file and Path(data_file).exists():
            result["actions"].append(f"åŠ è½½æ•°æ®æ–‡ä»¶: {data_file}")
            
            # ç”Ÿæˆåˆ†æä»£ç 
            analysis_code = f'''import pandas as pd
import numpy as np

# åŠ è½½æ•°æ®
df = pd.read_csv('{data_file}')

# åŸºæœ¬ç»Ÿè®¡
info = {{
    "shape": df.shape,
    "columns": list(df.columns),
    "dtypes": str(df.dtypes),
    "missing_values": df.isnull().sum().to_dict(),
    "describe": df.describe().to_dict()
}}

print("æ•°æ®å½¢çŠ¶:", df.shape)
print("åˆ—å:", list(df.columns))
print("ç¼ºå¤±å€¼:", df.isnull().sum())
print("ç»Ÿè®¡æè¿°:", df.describe())
'''
            
            result["actions"].append("ç”Ÿæˆæ•°æ®åˆ†æä»£ç ")
            result["outputs"].append({"type": "code", "content": analysis_code})
        
        result["status"] = "completed"
        return result
    
    def task_machine_learning(self, params: Dict) -> Dict:
        """æœºå™¨å­¦ä¹ ä»»åŠ¡"""
        logger.info("ğŸ¤– æ‰§è¡Œæœºå™¨å­¦ä¹ ä»»åŠ¡...")
        
        result = {
            "task": "machine_learning",
            "executed_at": datetime.now().isoformat(),
            "actions": [],
            "model_type": params.get("model", "unknown"),
            "outputs": []
        }
        
        model_type = params.get("model", "random_forest")
        
        # ç”Ÿæˆæ¨¡å‹è®­ç»ƒä»£ç 
        ml_code = f'''import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report

# åŠ è½½æ•°æ®
df = pd.read_csv('data.csv')
X = df.drop('target', axis=1)
y = df['target']

# åˆ’åˆ†æ•°æ®é›†
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# è®­ç»ƒæ¨¡å‹
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# é¢„æµ‹å’Œè¯„ä¼°
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)

print(f"æ¨¡å‹å‡†ç¡®ç‡: {{accuracy:.4f}}")
print(f"åˆ†ç±»æŠ¥å‘Š:\\n{{report}}")

# ç‰¹å¾é‡è¦æ€§
feature_importance = pd.DataFrame({{
    'feature': X.columns,
    'importance': model.feature_importances_
}}).sort_values('importance', ascending=False)

print("ç‰¹å¾é‡è¦æ€§:\\n{{feature_importance}}")
'''
        
        result["actions"].append(f"ç”Ÿæˆ{model_type}æ¨¡å‹è®­ç»ƒä»£ç ")
        result["outputs"].append({"type": "code", "content": ml_code})
        
        # ä¿å­˜ä»£ç 
        code_file = self.results_dir / f"ml_model_{int(time.time())}.py"
        code_file.write_text(ml_code, encoding='utf-8')
        result["outputs"].append({"type": "file", "path": str(code_file)})
        
        result["status"] = "completed"
        return result
    
    def task_deep_learning(self, params: Dict) -> Dict:
        """æ·±åº¦å­¦ä¹ ä»»åŠ¡"""
        logger.info("ğŸ§  æ‰§è¡Œæ·±åº¦å­¦ä¹ ä»»åŠ¡...")
        
        result = {
            "task": "deep_learning",
            "executed_at": datetime.now().isoformat(),
            "framework": params.get("framework", "pytorch"),
            "outputs": []
        }
        
        framework = params.get("framework", "pytorch")
        
        if framework == "pytorch":
            dl_code = '''import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset

# æ£€æŸ¥GPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"ä½¿ç”¨è®¾å¤‡: {{device}}")

# å®šä¹‰æ¨¡å‹
class NeuralNet(nn.Module):
    def __init__(self, input_size, hidden_size, num_classes):
        super().__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(hidden_size, num_classes)
    
    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        return self.fc2(x)

# è®­ç»ƒå¾ªç¯
model = NeuralNet(784, 256, 10).to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

for epoch in range(num_epochs):
    for batch_X, batch_y in train_loader:
        batch_X, batch_y = batch_X.to(device), batch_y.to(device)
        
        outputs = model(batch_X)
        loss = criterion(outputs, batch_y)
        
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
    
    if (epoch + 1) % 10 == 0:
        print(f'Epoch [{{epoch+1}}/{{num_epochs}}], Loss: {{loss.item():.4f}}')

print("è®­ç»ƒå®Œæˆ!")
'''
        
        result["outputs"].append({"type": "code", "content": dl_code})
        
        code_file = self.results_dir / f"dl_model_{int(time.time())}.py"
        code_file.write_text(dl_code, encoding='utf-8')
        result["outputs"].append({"type": "file", "path": str(code_file)})
        
        result["status"] = "completed"
        return result
    
    def task_nlp(self, params: Dict) -> Dict:
        """NLPä»»åŠ¡"""
        logger.info("ğŸ“ æ‰§è¡ŒNLPä»»åŠ¡...")
        
        result = {
            "task": "nlp",
            "executed_at": datetime.now().isoformat(),
            "task_type": params.get("type", "text_classification"),
            "outputs": []
        }
        
        nlp_code = '''from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
import pandas as pd

# æ–‡æœ¬åˆ†ç±»
classifier = pipeline("text-classification", model="bert-base-chinese")

texts = [
    "è¿™ä¸ªäº§å“éå¸¸å¥½ç”¨ï¼",
    "æœåŠ¡æ€åº¦å¾ˆå·®ï¼Œä¸æ¨è",
    "ä¸€èˆ¬èˆ¬å§ï¼Œè¿˜è¡Œ"
]

results = classifier(texts)
for text, result in zip(texts, results):
    print(f"æ–‡æœ¬: {{text}}")
    print(f"åˆ†ç±»: {{result['label']}}, ç½®ä¿¡åº¦: {{result['score']:.4f}}\\n")

# å‘½åå®ä½“è¯†åˆ«
ner = pipeline("ner", model="bert-base-chinese", aggregation_strategy="simple")
text = "å¼ ä¸‰åœ¨åŒ—äº¬å¤§å­¦å­¦ä¹ äººå·¥æ™ºèƒ½"
entities = ner(text)
for entity in entities:
    print(f"å®ä½“: {{entity['word']}}, ç±»å‹: {{entity['entity_group']}}, ç½®ä¿¡åº¦: {{entity['score']:.4f}}")
'''
        
        result["outputs"].append({"type": "code", "content": nlp_code})
        
        code_file = self.results_dir / f"nlp_task_{int(time.time())}.py"
        code_file.write_text(nlp_code, encoding='utf-8')
        result["outputs"].append({"type": "file", "path": str(code_file)})
        
        result["status"] = "completed"
        return result
    
    def task_write_code(self, params: Dict) -> Dict:
        """ç¼–å†™ä»£ç """
        logger.info("ğŸ’» æ‰§è¡Œä»£ç ç¼–å†™ä»»åŠ¡...")
        
        result = {
            "task": "write_code",
            "executed_at": datetime.now().isoformat(),
            "language": params.get("language", "python"),
            "description": params.get("description", ""),
            "outputs": []
        }
        
        language = params.get("language", "python")
        description = params.get("description", "è‡ªåŠ¨ç”Ÿæˆçš„ä»£ç ")
        
        if language == "python":
            code = f'''# {description}
# ç”Ÿæˆæ—¶é—´: {datetime.now().isoformat()}

import os
import json
from datetime import datetime

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æ‰§è¡Œ...")
    
    # ä½ çš„ä»£ç é€»è¾‘
    data = []
    
    for i in range(10):
        item = {{
            "id": i,
            "name": f"item_{{i}}",
            "timestamp": datetime.now().isoformat()
        }}
        data.append(item)
    
    # ä¿å­˜ç»“æœ
    with open("output.json", "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… å®Œæˆ! å¤„ç†äº† {{len(data)}} æ¡æ•°æ®")

if __name__ == "__main__":
    main()
'''
        elif language == "javascript":
            code = f'''// {description}
// Generated: {datetime.now().isoformat()}

const fs = require('fs');

async function main() {{
    console.log('ğŸš€ å¼€å§‹æ‰§è¡Œ...');
    
    const data = [];
    for (let i = 0; i < 10; i++) {{
        data.push({{
            id: i,
            name: `item_${{i}}`,
            timestamp: new Date().toISOString()
        }});
    }}
    
    fs.writeFileSync('output.json', JSON.stringify(data, null, 2));
    console.log(`âœ… å®Œæˆ! å¤„ç†äº† ${{data.length}} æ¡æ•°æ®`);
}}

main();
'''
        else:
            code = f"# {description}\n# Language: {language}"
        
        result["outputs"].append({"type": "code", "content": code})
        
        ext = {"python": "py", "javascript": "js", "java": "java", "cpp": "cpp"}.get(language, "txt")
        code_file = self.results_dir / f"generated_code_{int(time.time())}.{ext}"
        code_file.write_text(code, encoding='utf-8')
        result["outputs"].append({"type": "file", "path": str(code_file)})
        
        result["status"] = "completed"
        return result
    
    def task_debug_code(self, params: Dict) -> Dict:
        """ä»£ç è°ƒè¯•"""
        logger.info("ğŸ› æ‰§è¡Œä»£ç è°ƒè¯•ä»»åŠ¡...")
        
        result = {
            "task": "debug_code",
            "executed_at": datetime.now().isoformat(),
            "issues_found": [],
            "fixes_applied": [],
            "outputs": []
        }
        
        debug_script = '''#!/usr/bin/env python3
"""
ğŸ”§ ä»£ç è°ƒè¯•è„šæœ¬
è‡ªåŠ¨æ£€æµ‹å’Œä¿®å¤å¸¸è§é—®é¢˜
"""

import re
import sys

def check_common_issues(code: str) -> list:
    """æ£€æŸ¥å¸¸è§é—®é¢˜"""
    issues = []
    
    # æ£€æŸ¥TypeError: unsupported operand type(s)
    if re.search(r'\d+\s*[\+\-\*/]\s*[\'"]', code):
        issues.append({
            "type": "TypeError",
            "description": "æ£€æµ‹åˆ°æ•°å­—ä¸å­—ç¬¦ä¸²è¿ç®—",
            "fix": "ä½¿ç”¨str()æˆ–int()è¿›è¡Œç±»å‹è½¬æ¢"
        })
    
    # æ£€æŸ¥JSONåºåˆ—åŒ–float32
    if 'float32' in code:
        issues.append({
            "type": "JSONSerializationError",
            "description": "æ£€æµ‹åˆ°float32ç±»å‹",
            "fix": "ä½¿ç”¨float(x.item())æˆ–float(x)è¿›è¡Œè½¬æ¢"
        })
    
    # æ£€æŸ¥ç´¢å¼•è¶Šç•Œ
    if re.search(r'\[\-?\d+\]', code):
        issues.append({
            "type": "IndexError",
            "description": "æ£€æµ‹åˆ°åˆ—è¡¨ç´¢å¼•",
            "fix": "ç¡®ä¿ç´¢å¼•åœ¨æœ‰æ•ˆèŒƒå›´å†…"
        })
    
    return issues

def fix_issues(code: str, issues: list) -> str:
    """ä¿®å¤é—®é¢˜"""
    fixed_code = code
    
    # ä¿®å¤ç±»å‹è½¬æ¢
    fixed_code = re.sub(
        r'(\d+)\s*[\+\-]\s*[\'"]',
        r'str(\1) + ',
        fixed_code
    )
    
    # ä¿®å¤float32
    fixed_code = fixed_code.replace('float32', 'float')
    fixed_code = re.sub(r'\.item\(\)', '', fixed_code)
    
    return fixed_code

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    code = """
    import json
    import torch
    
    # æœ‰é—®é¢˜çš„ä»£ç 
    data = {{"value": torch.tensor([1.0])}}
    result = json.dumps(data)  # TypeError!
    """
    
    issues = check_common_issues(code)
    print(f"å‘ç°é—®é¢˜: {{len(issues)}} ä¸ª")
    
    for issue in issues:
        print(f"- {{issue['type']}}: {{issue['description']}}")
        print(f"  ä¿®å¤: {{issue['fix']}}")
'''
        
        result["outputs"].append({"type": "code", "content": debug_script})
        
        code_file = self.results_dir / f"debug_script_{int(time.time())}.py"
        code_file.write_text(debug_script, encoding='utf-8')
        result["outputs"].append({"type": "file", "path": str(code_file)})
        
        result["status"] = "completed"
        return result
    
    def task_learn_knowledge(self, params: Dict) -> Dict:
        """å­¦ä¹ æ–°çŸ¥è¯†"""
        logger.info("ğŸ“– æ‰§è¡ŒçŸ¥è¯†å­¦ä¹ ä»»åŠ¡...")
        
        result = {
            "task": "learn_knowledge",
            "executed_at": datetime.now().isoformat(),
            "topic": params.get("topic", "General Knowledge"),
            "source": params.get("source", "web_search"),
            "outputs": []
        }
        
        # ç”ŸæˆçŸ¥è¯†æ¡ç›®
        knowledge_entry = f'''# {result['topic']}

**å­¦ä¹ æ—¶é—´**: {datetime.now().isoformat()}
**æ¥æº**: {result['source']}
**æ ‡ç­¾**: AI, {result['topic']}

## æ ¸å¿ƒæ¦‚å¿µ

{params.get('content', 'è‡ªåŠ¨å­¦ä¹ çš„æ–°çŸ¥è¯†å†…å®¹')}

## å…³é”®çŸ¥è¯†ç‚¹

1. çŸ¥è¯†ç‚¹1: è¯´æ˜
2. çŸ¥è¯†ç‚¹2: è¯´æ˜
3. çŸ¥è¯†ç‚¹3: è¯´æ˜

## åº”ç”¨åœºæ™¯

- åœºæ™¯1: æè¿°
- åœºæ™¯2: æè¿°

## ç›¸å…³èµ„æº

- æ–‡æ¡£é“¾æ¥
- æ•™ç¨‹é“¾æ¥
- ä»£ç ç¤ºä¾‹

---

*ç”± OpenClaw AI Assistant è‡ªåŠ¨å­¦ä¹ *
'''
        
        # ä¿å­˜çŸ¥è¯†
        kb_dir = self.workspace / "knowledge"
        kb_dir.mkdir(exist_ok=True)
        
        topic_file = kb_dir / f"{result['topic'].replace(' ', '_')}_{int(time.time())}.md"
        topic_file.write_text(knowledge_entry, encoding='utf-8')
        
        result["outputs"].append({"type": "knowledge_file", "path": str(topic_file)})
        result["status"] = "completed"
        return result
    
    def task_update_knowledge(self, params: Dict) -> Dict:
        """æ›´æ–°çŸ¥è¯†åº“"""
        logger.info("ğŸ”„ æ‰§è¡ŒçŸ¥è¯†åº“æ›´æ–°ä»»åŠ¡...")
        
        result = {
            "task": "update_knowledge",
            "executed_at": datetime.now().isoformat(),
            "actions": [],
            "outputs": []
        }
        
        kb_dir = self.workspace / "knowledge"
        kb_files = list(kb_dir.glob("*.md"))
        
        result["actions"].append(f"æ‰«æçŸ¥è¯†åº“: {len(kb_files)} ä¸ªæ–‡ä»¶")
        
        # ç”Ÿæˆæ±‡æ€»
        summary = f'''# çŸ¥è¯†åº“æ±‡æ€»

**æ›´æ–°æ—¶é—´**: {datetime.now().isoformat()}
**æ–‡ä»¶æ•°**: {len(kb_files)}

## æ–‡ä»¶åˆ—è¡¨

'''
        for f in sorted(kb_files):
            summary += f"- {f.name}\n"
        
        summary_file = kb_dir / "knowledge_summary.md"
        summary_file.write_text(summary, encoding='utf-8')
        
        result["actions"].append("ç”ŸæˆçŸ¥è¯†åº“æ±‡æ€»")
        result["outputs"].append({"type": "summary_file", "path": str(summary_file)})
        result["status"] = "completed"
        return result
    
    def task_generate_report(self, params: Dict) -> Dict:
        """ç”ŸæˆæŠ¥å‘Š"""
        logger.info("ğŸ“Š æ‰§è¡ŒæŠ¥å‘Šç”Ÿæˆä»»åŠ¡...")
        
        result = {
            "task": "generate_report",
            "executed_at": datetime.now().isoformat(),
            "report_type": params.get("type", "status"),
            "outputs": []
        }
        
        # ç”ŸæˆçŠ¶æ€æŠ¥å‘Š
        report = f'''# OpenClaw AI Assistant çŠ¶æ€æŠ¥å‘Š

**ç”Ÿæˆæ—¶é—´**: {datetime.now().isoformat()}

## ğŸ“Š ä»»åŠ¡æ‰§è¡Œç»Ÿè®¡

- æ€»æ‰§è¡Œæ¬¡æ•°: {len(self.execution_history)}
- æˆåŠŸæ¬¡æ•°: {sum(1 for e in self.execution_history if e['status'] == 'success')}
- å¤±è´¥æ¬¡æ•°: {sum(1 for e in self.execution_history if e['status'] == 'failed')}

## ğŸ“ æœ€è¿‘æ‰§è¡Œè®°å½•

'''
        for entry in self.execution_history[-10:]:
            status_emoji = "âœ…" if entry['status'] == 'success' else "âŒ"
            report += f"{status_emoji} {entry['timestamp']} - {entry['task']}\n"
        
        report_file = self.workspace / f"report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        report_file.write_text(report, encoding='utf-8')
        
        result["outputs"].append({"type": "report_file", "path": str(report_file)})
        result["status"] = "completed"
        return result
    
    def task_organize_files(self, params: Dict) -> Dict:
        """æ–‡ä»¶æ•´ç†"""
        logger.info("ğŸ“ æ‰§è¡Œæ–‡ä»¶æ•´ç†ä»»åŠ¡...")
        
        result = {
            "task": "organize_files",
            "executed_at": datetime.now().isoformat(),
            "actions": [],
            "outputs": []
        }
        
        target_dir = Path(params.get("directory", str(self.workspace)))
        pattern = params.get("pattern", "*.py")
        
        files = list(target_dir.glob(pattern))
        result["actions"].append(f"å‘ç° {len(files)} ä¸ªåŒ¹é…æ–‡ä»¶")
        
        # æŒ‰ç±»å‹åˆ†ç»„
        file_groups = {}
        for f in files:
            ext = f.suffix
            if ext not in file_groups:
                file_groups[ext] = []
            file_groups[ext].append(f.name)
        
        result["actions"].append(f"åˆ†ç»„: {list(file_groups.keys())}")
        result["outputs"].append({"type": "file_groups", "groups": {k: len(v) for k, v in file_groups.items()}})
        
        result["status"] = "completed"
        return result
    
    def task_web_search(self, params: Dict) -> Dict:
        """ç½‘ç»œæœç´¢"""
        logger.info("ğŸŒ æ‰§è¡Œç½‘ç»œæœç´¢ä»»åŠ¡...")
        
        result = {
            "task": "web_search",
            "executed_at": datetime.now().isoformat(),
            "query": params.get("query", ""),
            "outputs": []
        }
        
        # æ¨¡æ‹Ÿæœç´¢ç»“æœ
        search_results = f'''# æœç´¢ç»“æœ: {result['query']}

**æœç´¢æ—¶é—´**: {datetime.now().isoformat()}

## ç›¸å…³ç»“æœ

1. ç»“æœ1 - æè¿°
2. ç»“æœ2 - æè¿°
3. ç»“æœ3 - æè¿°

## æ³¨æ„äº‹é¡¹

- ç½‘ç»œæœç´¢éœ€è¦é…ç½® Brave API Key
- è¿è¡Œ: openclaw configure --section web
- æˆ–è®¾ç½®ç¯å¢ƒå˜é‡: BRAVE_API_KEY

---
'''
        result["outputs"].append({"type": "search_results", "content": search_results})
        result["status"] = "completed"
        return result
    
    def task_run_script(self, params: Dict) -> Dict:
        """è¿è¡Œè„šæœ¬"""
        logger.info("âš¡ æ‰§è¡Œè„šæœ¬è¿è¡Œä»»åŠ¡...")
        
        result = {
            "task": "run_script",
            "executed_at": datetime.now().isoformat(),
            "script": params.get("script", ""),
            "outputs": []
        }
        
        script = params.get("script")
        if script and Path(script).exists():
            try:
                # è¿è¡Œè„šæœ¬
                result["outputs"].append({"type": "script_path", "path": script})
                result["status"] = "completed"
            except Exception as e:
                result["error"] = str(e)
                result["status"] = "failed"
        else:
            result["error"] = "è„šæœ¬æ–‡ä»¶ä¸å­˜åœ¨"
            result["status"] = "failed"
        
        return result


def main():
    """ä¸»å‡½æ•° - æµ‹è¯•ä»»åŠ¡æ‰§è¡Œå™¨"""
    print("ğŸš€ å¯åŠ¨ TaskExecutor...")
    
    executor = TaskExecutor()
    
    # æµ‹è¯•æ‰§è¡Œå‡ ä¸ªä»»åŠ¡
    print("\nğŸ“‹ æµ‹è¯•ä»»åŠ¡æ‰§è¡Œ:")
    
    # 1. ç¼–å†™ä»£ç 
    print("\n1. æµ‹è¯•ä»£ç ç¼–å†™:")
    result1 = executor.execute("ç¼–å†™ä»£ç ", {
        "language": "python",
        "description": "æ•°æ®å¤„ç†è„šæœ¬"
    })
    print(f"   çŠ¶æ€: {result1['status']}")
    
    # 2. æœºå™¨å­¦ä¹ 
    print("\n2. æµ‹è¯•æœºå™¨å­¦ä¹ ä»£ç ç”Ÿæˆ:")
    result2 = executor.execute("æœºå™¨å­¦ä¹ ", {
        "model": "random_forest"
    })
    print(f"   çŠ¶æ€: {result2['status']}")
    
    # 3. æ·±åº¦å­¦ä¹ 
    print("\n3. æµ‹è¯•æ·±åº¦å­¦ä¹ ä»£ç ç”Ÿæˆ:")
    result3 = executor.execute("æ·±åº¦å­¦ä¹ ", {
        "framework": "pytorch"
    })
    print(f"   çŠ¶æ€: {result3['status']}")
    
    # 4. ç”ŸæˆæŠ¥å‘Š
    print("\n4. æµ‹è¯•æŠ¥å‘Šç”Ÿæˆ:")
    result4 = executor.execute("ç”ŸæˆæŠ¥å‘Š", {
        "type": "status"
    })
    print(f"   çŠ¶æ€: {result4['status']}")
    
    print("\nâœ… æµ‹è¯•å®Œæˆ!")
    print(f"ğŸ“Š æ‰§è¡Œå†å²: {len(executor.execution_history)} æ¡è®°å½•")


if __name__ == "__main__":
    main()
